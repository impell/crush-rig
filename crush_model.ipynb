{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crush Rig Predictive Models\n",
    "* __Classifier for Trauma Score__\n",
    "* __Regressor for serosa thickness delta__\n",
    "\n",
    "Written by Matt MacDonald for CIGITI at the Hospital for Sick Children Toronto\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All tools to manipulate data will be obtained from the crush_plot.py file. The objective of this notebook is to predict the histological targets from the force/position crush data using a classifier, either logistic regression or otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.dpi'] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdb import set_trace\n",
    "from warnings import warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crush data must be collected using the crush rig and crush.py and stored in the expected folder structure at the root directory indicated by PATH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crush_read import *\n",
    "from crush_plot import *\n",
    "PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all data and modify as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = study_outline(PATH)\n",
    "targets = study_targets(PATH)\n",
    "crushes = study_data(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crushes = modify(crushes)\n",
    "crushes = calculate(crushes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = random(crushes)\n",
    "time_plot(c, trim=False)\n",
    "time_plot(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data for model training and confirm no NaN issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, legend = preprocess(crushes, targets)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Reference for categorical features:')\n",
    "legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the holding strain feature since only the STOP protocol is being considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop('Holding Strain', axis=1)\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crush duration is heavily correlated with thickness because of how thickness is calculated by the position above the crush platform at the contact time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[['Thickness (mm)', 'Crush Duration (s)']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate matrix of correlations to aid understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focus on the two targets being investigated in the analysis: \n",
    "* serosa thickness change significance\n",
    "* pathologist trauma score rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_targets = y[['P Score', 'Trauma Score']].copy()\n",
    "key_targets = key_targets.rename(columns={'P Score': 'Serosa Change Significance'})\n",
    "key_targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([X, key_targets], axis=1).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(pd.concat([X, key_targets], axis=1).corr(), center=0, vmin=-1, vmax=1, cmap='RdBu');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting correlations:\n",
    "- target stress is strongly correlated with trauma score and p score as expected\n",
    "- target stress is not correlated with the absolute thickness change, likely because of serosal variability in patients\n",
    "- strain and stiffness metrics are correlated with the thickness and tissue type of the sample\n",
    "- trauma score and p score correlate, proving a relationship between the pathologist opinion and serosal thickness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the trauma score and serosa thickness metric correlations more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_targets.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(key_targets.corr(), center=0, vmin=-1, vmax=1, cmap='RdBu');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_targets.sort_values('Serosa Change Significance').plot(x='Serosa Change Significance', y='Trauma Score', kind='scatter', alpha=0.5);\n",
    "plt.yticks([0, 1, 2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look for anomalies in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Crush Duration (s)'].plot(style='.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long = X['Crush Duration (s)'] > 35\n",
    "long.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_plot(crushes[long], trim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[long]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contact stiffness is low for this sample due to the incorrect trigger for intial contact time. The calculated thickness is also erroneously high. Most other figures are okay however so it is not a huge issue. The source of the error was the crush rig detecting contact too early as a false positive. This would have to be fixed in teh source data if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X['Thickness (mm)'] > 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare binary classification targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = binary_classes(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_targets = y.columns[4:]\n",
    "for col in classifier_targets:\n",
    "    most_common = y[col].value_counts().idxmax()\n",
    "    s = (y[col] == most_common).sum()\n",
    "    c = y[col].count()\n",
    "    r = s / c\n",
    "    print(f\"{col}\\n    - baseline accuracy = {s}/{c} ({r:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y['Tissue Damage'] == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['Tissue Damage'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['Major Tissue Damage'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The major tissue damage target is unbalanced. It may not be enough data for an accurate classifier due to the skewed distribution of positive samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "trauma_score = y['Tissue Damage'].copy()\n",
    "trauma_score[y['Major Tissue Damage']] = 2\n",
    "serosa_delta = y['Percent Serosa Change']\n",
    "plt.scatter(serosa_delta, trauma_score, color='indigo')\n",
    "plt.ylabel('Tissue Trauma Score')\n",
    "plt.xlabel('Percent Serosa Change')\n",
    "plt.yticks([0, 1, 2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 1))\n",
    "plt.scatter(100 * y['Percent Serosa Change'], y['Tissue Damage'], color='indigo', alpha=0.25, s=100)\n",
    "plt.xlabel('Serosa Thickness Change (%)')\n",
    "plt.yticks([0, 1], ['No Trauma', 'Trauma'])\n",
    "plt.ylim([-0.5, 1.5]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see colon vs small bowel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_mask = X['Tissue'] == False\n",
    "sb_mask = X['Tissue'] == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 1))\n",
    "plt.scatter(100 * y[col_mask]['Percent Serosa Change'], y[col_mask]['Tissue Damage'], color='indigo', alpha=0.25, s=100)\n",
    "plt.xlabel('Serosa Thickness Change (%)')\n",
    "plt.yticks([0, 1], ['No Trauma', 'Trauma'])\n",
    "plt.ylim([-0.5, 1.5])\n",
    "plt.title('Colon');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 1))\n",
    "plt.scatter(100 * y[sb_mask]['Percent Serosa Change'], y[sb_mask]['Tissue Damage'], color='indigo', alpha=0.25, s=100)\n",
    "plt.xlabel('Serosa Thickness Change (%)')\n",
    "plt.yticks([0, 1], ['No Trauma', 'Tissue Trauma'])\n",
    "plt.ylim([-0.5, 1.5])\n",
    "plt.title('Small Bowel');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "s = 0.25\n",
    "m = y.shape[0]\n",
    "y1 = y['Tissue Damage']\n",
    "y2 = y['Significant Serosa Change']\n",
    "rx = np.random.rand(m) * s - (s / 2)\n",
    "ry = np.random.rand(m) * s - (s / 2)\n",
    "plt.scatter(x=y1 + rx, y=y2 + ry, color='seagreen', alpha=0.25, s=100)\n",
    "plt.xticks([0, 1], ['No Trauma', 'Trauma'])\n",
    "plt.yticks([0, 1], ['Not Significant', 'Significant'])\n",
    "plt.xlim([-0.5, 1.5])\n",
    "plt.ylim([-0.5, 1.5])\n",
    "plt.title('Serosa Thickness Change vs. Trauma Score')\n",
    "\n",
    "cnts = [sum([x != y for x, y in zip(y1, y2) if x == 0]),\n",
    "        sum([x == y for x, y in zip(y1, y2) if x == 1]),\n",
    "        sum([x == y for x, y in zip(y1, y2) if x == 0]),\n",
    "        sum([x != y for x, y in zip(y1, y2) if x == 1])]\n",
    "\n",
    "plt.text(-0.08, 1.25, f\"n={cnts[0]} ({100 * cnts[0] / m:.0f}%)\", size=10)\n",
    "plt.text(0.92, 1.25, f\"n={cnts[1]} ({100 * cnts[1] / m:.0f}%)\", size=10)\n",
    "plt.text(-0.08, 0.25, f\"n={cnts[2]} ({100 * cnts[2] / m:.0f}%)\", size=10)\n",
    "plt.text(0.92, 0.25, f\"n={cnts[3]} ({100 * cnts[3] / m:.0f}%)\", size=10)\n",
    "\n",
    "print('Top left N = {} / {}'.format(cnts[0], m))\n",
    "print('Top right N = {} / {}'.format(cnts[1], m))\n",
    "print('Bottom left N = {} / {}'.format(cnts[2], m))\n",
    "print('Bottom right N = {} / {}'.format(cnts[3], m))\n",
    "print('Agreement = {} / {}'.format(sum(cnts[1:3]), m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the key variable which is target stress. Below is the corresponding load in grams for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_to_megapascal(load):\n",
    "    return (9.81 * load) / (1000 * np.pi * (5/2)** 2)  # 5mm pin\n",
    "\n",
    "def megapascal_to_gram(load):\n",
    "    return (1000 * np.pi * (5/2)** 2) * load / 9.81  # 5mm pin\n",
    "\n",
    "for load in [200, 400, 600, 800, 1000, 1200]:  # test loads in grams\n",
    "    print(f\"{gram_to_megapascal(load):6.2f} (MPa) = {load:5} (grams)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_name = 'Target Stress (MPa)'\n",
    "for y_name in y.columns:\n",
    "    plt.figure()\n",
    "    plt.scatter(x=X[x_name], y=y[y_name], alpha=0.25, s=100)\n",
    "    plt.xlabel(x_name)\n",
    "    plt.ylabel(y_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal for the prediction algorithm is to provide a metric for preventing tissue damage intraoperatively. Thus it has the following requirements:\n",
    "\n",
    "1. Good overall accuracy so it is reliable without being restrictive\n",
    "2. High recall such that it is conservative, limiting the occurrence of false negatives\n",
    "3. Simple with limited input so that it can be implemented cheaply in real time\n",
    "\n",
    "Further to requirement 3 above, no histology features can be used to make the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq(crush):\n",
    "    time = crush.index\n",
    "    delta = time[1:] - time[:-1]\n",
    "    return 1 / np.mean(delta.total_seconds())\n",
    "\n",
    "freqs = crushes['Data'].apply(get_freq)\n",
    "freqs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample frequency is 31 Hz\n",
    "\n",
    "Nyquist frequency is 62 Hz\n",
    "\n",
    "Cutoff frequency of 3rd order butterworth digital filter is 0.2 * 62 = 12.4 Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "Define the targets and set the random seed for the model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed = SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['Percent Serosa Change',  # regression\n",
    "           'Significant Serosa Change',\n",
    "           'Tissue Damage',\n",
    "           'Major Tissue Damage']\n",
    "\n",
    "class_labels = {'Percent Serosa Change': None,\n",
    "                'Significant Serosa Change': ['No Change', 'Significant Change'],\n",
    "                'Tissue Damage': ['No Damage', 'Damage'],\n",
    "                'Major Tissue Damage': ['No Damage or Minor Damage', 'Major Damage']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, targ in enumerate(targets):\n",
    "    print(i, targ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_np = X.values.astype(np.float64)\n",
    "y_np = y[targets].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_np, y_np, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizing the features makes the final model harder to apply and interpret manually. So it is not advisable in this case. Similarly for PCA which will make feature importances hard to determine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train).boxplot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X.columns.values\n",
    "for i, feat in enumerate(features):\n",
    "    print(i, feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_feat = 6\n",
    "features[stress_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_feat = 5\n",
    "features[duration_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thickness_feat = 3\n",
    "features[thickness_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_feat = 7\n",
    "features[strain_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue_feat = 0\n",
    "features[tissue_feat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prep\n",
    "Create functions needed for fitting predictive models to the data.\n",
    "\n",
    "For classification we will use logistic regression due to it's long standing success as a binary classification model for medical data. For regression we will rely on lasso regression to take advantage of the feature selection behaviour given the number of low correlation features in the dataset. Both are also simple enough to be practical for hand calculations or lookup tables in the OR and are interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, roc_auc_score, mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lasso(X, y):\n",
    "    # Fit regressor using cross validation and l1 loss\n",
    "    model = LassoCV(n_alphas=10, cv=5, random_state=SEED)\n",
    "    return model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_logreg(X, y):\n",
    "\n",
    "    # Model\n",
    "    model = LogisticRegression(multi_class='auto', random_state=SEED, solver='liblinear', max_iter=5000)\n",
    "\n",
    "    # Hyperparameter tuning\n",
    "    param_grid = [{}]\n",
    "    param_grid[0][\"penalty\"] = ['l1', 'l2']\n",
    "    param_grid[0][\"C\"] = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30]\n",
    "    param_grid[0][\"class_weight\"] = [None, 'balanced']\n",
    "\n",
    "    # Perform grid search\n",
    "    clf = GridSearchCV(estimator=model, cv=5, refit=True,\n",
    "                       param_grid=param_grid, verbose=1, scoring='balanced_accuracy')\n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fit(X, y, model, target):\n",
    "    best_feat = np.argmax(np.abs(model.coef_)) \n",
    "    plt.figure()\n",
    "    plt.plot(X[:, best_feat], model.predict(X), 'k.')\n",
    "    plt.scatter(X[:, best_feat], y, alpha=0.25, s=100)\n",
    "    plt.xlabel(stress_feature)  # assumed to be best feature\n",
    "    plt.ylabel(target)\n",
    "    plt.legend(['Predicted', 'Actual'])\n",
    "    plt.show()\n",
    "\n",
    "def assess_lasso(X, y, model, target):\n",
    "    # RMSE and fit curve for regressors\n",
    "        plot_fit(X, y, model, target)\n",
    "        \n",
    "        return {'RMSE': np.sqrt(mean_squared_error(y, model.predict(X)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_auc(X, y, model, target):\n",
    "    plt.figure()\n",
    "    plt.plot(*roc_curve(y, model.predict_proba(X)[:, 1])[:2],\n",
    "             label=f\"ROC curve (AUC = {roc_auc_score(y, model.predict(X)):.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([-0.05, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title(target)\n",
    "    plt.show()\n",
    "\n",
    "def assess_logreg(X, y, model, target):       \n",
    "    \n",
    "    # Classification metrics and AUC for classifiers\n",
    "    plot_auc(X, y, model, target)\n",
    "    report = classification_report(y, model.predict(X),\n",
    "                                   digits=3,\n",
    "                                   output_dict=True)\n",
    "\n",
    "    return report['1.0']  # positive calss only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DELETE??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE, RFECV\n",
    "\n",
    "def optimal_reg(X, y, target, n_features=None):\n",
    "    # Restrict the features used to get a simpler model\n",
    "    \n",
    "    # Lasso and MSE for regression\n",
    "    if class_labels[target] is None:\n",
    "        model = lasso_reg(X, y)\n",
    "        if n_features is not None:\n",
    "            rfe = RFE(model, n_features_to_select=n_features)\n",
    "        else:\n",
    "            rfe = RFECV(model, cv=5, scoring='neg_mean_squared_error', n_jobs=4)\n",
    "    \n",
    "    # Logistic regression and accuracy for classification\n",
    "    else:\n",
    "        model = logit_reg(X, y)\n",
    "        if n_features is not None:\n",
    "            rfe = RFE(model, n_features_to_select=n_features)\n",
    "        else:\n",
    "            rfe = RFECV(model, cv=5, scoring='accuracy', n_jobs=4)\n",
    "    \n",
    "    return rfe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(X, y, model, n_features=None):\n",
    "    '''\n",
    "    Convenient function  to build multiple models\n",
    "    Remove any features deemed to be irrelevent by recursive feature elimination\n",
    "    '''\n",
    "    if n_features is None:\n",
    "        n_features = X.shape[1]\n",
    "    rfe = restricted_reg(X, y, model, n_features)\n",
    "    \n",
    "    # Rank the features\n",
    "    rank = pd.DataFrame({'features': features,\n",
    "                         'ranking': rfe.ranking_})\n",
    "    rank = rank.sort_values(by='ranking')\n",
    "    selected = rank.features[:n_features].tolist()\n",
    "    \n",
    "    # Train the model once more on just the selected features\n",
    "    mask = rfe.support_\n",
    "    model = logit_reg(X[:, mask], y)\n",
    "    \n",
    "    return {'model': model,\n",
    "            'rank': rank,\n",
    "            'features': selected,\n",
    "            'n_features': n_features}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "Build linear regression model for the continuous targets. Build logistic regression models for the class target values.\n",
    "\n",
    "### Percent Change in Serosa Thickness\n",
    "Regression model with Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "targets[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_lasso(X_train, y_train[:, idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_lasso(X_train, y_train[:, idx], model, targets[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_lasso(X_test, y_test[:, idx], model, targets[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.DataFrame(np.vstack([features, np.abs(model.coef_)]).T, columns= ['Feature', 'Coefficient'])\n",
    "feat_importances = feat_importances.sort_values('Coefficient', ascending=True).set_index('Feature')\n",
    "feat_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances.plot.barh();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does it perform with just the target stress to work with?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_single = X_train[:, stress_feat].reshape(-1, 1)\n",
    "X_test_single = X_test[:, stress_feat].reshape(-1, 1)\n",
    "model = build_lasso(X_train_single, y_train[:, idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_lasso(X_train_single, y_train[:, idx], model, targets[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_lasso(X_test_single, y_test[:, idx], model, targets[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significant Change in Serosa Thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = build_logreg(X_train, y_train[:, idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_logreg(X_train, y_train[:, idx], clf, targets[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_logreg(X_test, y_test[:, idx], clf, targets[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.DataFrame(np.vstack([features, np.abs(clf.best_estimator_.coef_)]).T, columns= ['Feature', 'Coefficient'])\n",
    "feat_importances = feat_importances.sort_values('Coefficient', ascending=True).set_index('Feature')\n",
    "feat_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances.plot.barh();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does it perform with just the target stress to work with?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_single = X_train[:, stress_feat].reshape(-1, 1)\n",
    "X_test_single = X_test[:, stress_feat].reshape(-1, 1)\n",
    "clf = build_logreg(X_train_single, y_train[:, idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_logreg(X_train_single, y_train[:, idx], clf, targets[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_logreg(X_test_single, y_test[:, idx], clf, targets[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no measureable difference if duration is included along with target stress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = build_logreg(X_train[:, [stress_feat, duration_feat]], y_train[:, idx])\n",
    "assess_logreg(X_test[:, [stress_feat, duration_feat]], y_test[:, idx], clf, targets[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, including the thickness makes no measureable difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = build_logreg(X_train[:, [stress_feat, duration_feat, thickness_feat]], y_train[:, idx])\n",
    "assess_logreg(X_test[:, [stress_feat, duration_feat, thickness_feat]], y_test[:, idx], clf, targets[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the model parameters for the target stress only model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = build_logreg(X_train_single, y_train[:, idx])\n",
    "model = clf.best_estimator_\n",
    "print('Model coefficients:')\n",
    "print(model.coef_)\n",
    "print('Model features:')\n",
    "print(features[stress_feat])\n",
    "print('Model intercept:')\n",
    "print(model.intercept_)\n",
    "print('Model parameters:')\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where does the model predict significant serosa thickness change then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress = np.linspace(0, 1, 1000).reshape(-1, 1)\n",
    "pred = model.predict(stress)\n",
    "prob = model.predict_proba(stress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stress[np.argmax(pred)] * 1000, 'kPa limit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(megapascal_to_gram(stress[np.argmax(pred)]), 'gram limit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(stress, pred)\n",
    "plt.scatter(stress, prob[:, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tissue Damage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = build_logreg(X_train, y_train[:, idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_logreg(X_train, y_train[:, idx], clf, targets[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_logreg(X_test, y_test[:, idx], clf, targets[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.DataFrame(np.vstack([features, np.abs(clf.best_estimator_.coef_)]).T, columns= ['Feature', 'Coefficient'])\n",
    "feat_importances = feat_importances.sort_values('Coefficient', ascending=True).set_index('Feature')\n",
    "feat_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances.plot.barh();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does it perform with just the target stress to work with?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_single = X_train[:, stress_feat].reshape(-1, 1)\n",
    "X_test_single = X_test[:, stress_feat].reshape(-1, 1)\n",
    "clf = build_logreg(X_train_single, y_train[:, idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_logreg(X_train_single, y_train[:, idx], clf, targets[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_logreg(X_test_single, y_test[:, idx], clf, targets[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a measureable difference if strain is included along with target stress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = build_logreg(X_train[:, [stress_feat, strain_feat]], y_train[:, idx])\n",
    "assess_logreg(X_test[:, [stress_feat, strain_feat]], y_test[:, idx], clf, targets[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a slight degradation in performance if the tissue type is included as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = build_logreg(X_train[:, [stress_feat, strain_feat, tissue_feat]], y_train[:, idx])\n",
    "assess_logreg(X_test[:, [stress_feat, strain_feat, tissue_feat]], y_test[:, idx], clf, targets[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the model parameters for the target stress only model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = build_logreg(X_train_single, y_train[:, idx])\n",
    "model = clf.best_estimator_\n",
    "print('Model coefficients:')\n",
    "print(model.coef_)\n",
    "print('Model features:')\n",
    "print(features[stress_feat])\n",
    "print('Model intercept:')\n",
    "print(model.intercept_)\n",
    "print('Model parameters:')\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where does the model predict significant serosa thickness change then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress = np.linspace(0, 1, 1000).reshape(-1, 1)\n",
    "pred = model.predict(stress)\n",
    "prob = model.predict_proba(stress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stress[np.argmax(pred)] * 1000, 'kPa limit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(megapascal_to_gram(stress[np.argmax(pred)]), 'gram limit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(stress, pred)\n",
    "plt.scatter(stress, prob[:, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Major Tissue Damage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a specific indicator from the targets and split the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3\n",
    "targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = build_logreg(X_train, y_train[:, idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:, idx].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 4 positive examples for major damage!! That is far too few to build a useable model as feared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier\n",
    "Combining the two single models may make a more powerful model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "serosa_model = build_logreg(X_train_single, y_train[:, 1]).best_estimator_\n",
    "trauma_model = build_logreg(X_train_single, y_train[:, 2]).best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trauma score rating as the golden standard target\n",
    "voting_clf = VotingClassifier([('Serosa', serosa_model), ('Trauma', trauma_model)], voting='soft')\n",
    "voting_clf.fit(X_train_single, y_train[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_logreg(X_train_single, y_train[:, 2], voting_clf, targets[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_logreg(X_test_single, y_test[:, 2], voting_clf, targets[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, voting with a single feature does not improve the outcome. The same is seen if all features are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serosa_model = build_logreg(X_train, y_train[:, 1]).best_estimator_\n",
    "trauma_model = build_logreg(X_train, y_train[:, 2]).best_estimator_\n",
    "voting_clf = VotingClassifier([('Serosa', serosa_model), ('Trauma', trauma_model)], voting='soft')\n",
    "voting_clf.fit(X_train, y_train[:, 2])\n",
    "assess_logreg(X_test, y_test[:, 2], voting_clf, targets[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at disagreements between models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
