{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crush Rig Predictive Models\n",
    "* __Classifier for Trauma Score__\n",
    "* __Regressor for serosa thickness delta__\n",
    "\n",
    "Written by Matt MacDonald for CIGITI at the Hospital for Sick Children Toronto\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All tools to manipulate data will be obtained from the crush_plot.py file. The objective of this notebook is to predict the histological targets from the force/position crush data using a classifier, either logistic regression or otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.dpi'] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdb import set_trace\n",
    "from warnings import warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crush data must be collected using the crush rig and crush.py and stored in the expected folder structure at the root directory indicated by PATH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crush_read import *\n",
    "from crush_plot import *\n",
    "PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all data and modify as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = study_outline(PATH)\n",
    "targets = study_targets(PATH)\n",
    "crushes = study_data(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crushes = modify(crushes)\n",
    "crushes = calculate(crushes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = random(crushes)\n",
    "time_plot(c, trim=False)\n",
    "time_plot(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data for model training and confirm no NaN issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, legend = preprocess(crushes, targets)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Reference for categorical features:')\n",
    "legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the holding strain feature since only the STOP protocol is being considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop('Holding Strain', axis=1)\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crush duration is heavily correlated with thickness because of how thickness is calculated by the position above the crush platform at the contact time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[['Thickness (mm)', 'Crush Duration (s)']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate matrix of correlations to aid understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_targets = y[['Percent Serosa Change', 'P Score', 'Trauma Score']].copy()\n",
    "key_targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([X, key_targets], axis=1).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(pd.concat([X, key_targets], axis=1).corr(), center=0, vmin=-1, vmax=1, cmap='RdBu');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting correlations:\n",
    "- target stress is strongly correlated with trauma score and p score as expected\n",
    "- target stress is not correlated with the absolute thickness change, likely because of serosal variability in patients\n",
    "- strain and stiffness metrics are correlated with the thickness and tissue type of the sample\n",
    "- trauma score and p score correlate, proving a relationship between the pathologist opinion and serosal thickness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the trauma score and serosa thickness metric correlations more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_targets.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(key_targets.corr(), center=0, vmin=-1, vmax=1, cmap='RdBu');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_targets.sort_values('P Score').plot(x='P Score', y='Trauma Score', kind='scatter', alpha=0.5);\n",
    "plt.yticks([0, 1, 2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_targets.sort_values('Percent Serosa Change').plot(x='Percent Serosa Change', y='Trauma Score', kind='scatter', alpha=0.5);\n",
    "plt.yticks([0, 1, 2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look for anomalies in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Crush Duration (s)'].plot(style='.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long = X['Crush Duration (s)'] > 35\n",
    "long.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_plot(crushes[long], trim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[long]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contact stiffness is low for this sample due to the incorrect trigger for intial contact time. The calculated thickness is also erroneously high. Most other figures are okay however so it is not a huge issue. The source of the error was the crush rig detecting contact too early as a false positive. This would have to be fixed in teh source data if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X['Thickness (mm)'] > 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare binary classification targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = binary_classes(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_targets = y.columns[4:]\n",
    "for col in classifier_targets:\n",
    "    most_common = y[col].value_counts().idxmax()\n",
    "    s = (y[col] == most_common).sum()\n",
    "    c = y[col].count()\n",
    "    r = s / c\n",
    "    print(f\"{col}\\n    - baseline accuracy = {s}/{c} ({r:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The major tissue damage target is unbalanced. It may not be enough data for an accurate classifier due to the skewed distribution of positive samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "trauma_score = y['Tissue Damage'].copy()\n",
    "trauma_score[y['Major Tissue Damage']] = 2\n",
    "serosa_delta = y['Percent Serosa Change']\n",
    "plt.scatter(serosa_delta, trauma_score, color='indigo')\n",
    "plt.ylabel('Tissue Trauma Score')\n",
    "plt.xlabel('Percent Serosa Change')\n",
    "plt.yticks([0, 1, 2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 1))\n",
    "plt.scatter(100 * y['Percent Serosa Change'], y['Tissue Damage'], color='indigo', alpha=0.25, s=100)\n",
    "plt.xlabel('Serosa Thickness Change (%)')\n",
    "plt.yticks([0, 1], ['No Trauma', 'Trauma'])\n",
    "plt.ylim([-0.5, 1.5]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see colon vs small bowel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_mask = X['Tissue'] == False\n",
    "sb_mask = X['Tissue'] == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 1))\n",
    "plt.scatter(100 * y[col_mask]['Percent Serosa Change'], y[col_mask]['Tissue Damage'], color='indigo', alpha=0.25, s=100)\n",
    "plt.xlabel('Serosa Thickness Change (%)')\n",
    "plt.yticks([0, 1], ['No Trauma', 'Trauma'])\n",
    "plt.ylim([-0.5, 1.5])\n",
    "plt.title('Colon');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 1))\n",
    "plt.scatter(100 * y[sb_mask]['Percent Serosa Change'], y[sb_mask]['Tissue Damage'], color='indigo', alpha=0.25, s=100)\n",
    "plt.xlabel('Serosa Thickness Change (%)')\n",
    "plt.yticks([0, 1], ['No Trauma', 'Tissue Trauma'])\n",
    "plt.ylim([-0.5, 1.5])\n",
    "plt.title('Small Bowel');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "s = 0.25\n",
    "m = y.shape[0]\n",
    "y1 = y['Tissue Damage']\n",
    "y2 = y['Significant Serosa Change']\n",
    "rx = np.random.rand(m) * s - (s / 2)\n",
    "ry = np.random.rand(m) * s - (s / 2)\n",
    "plt.scatter(x=y1 + rx, y=y2 + ry, color='seagreen', alpha=0.25, s=100)\n",
    "plt.xticks([0, 1], ['No Trauma', 'Trauma'])\n",
    "plt.yticks([0, 1], ['Not Significant', 'Significant'])\n",
    "plt.xlim([-0.5, 1.5])\n",
    "plt.ylim([-0.5, 1.5])\n",
    "plt.title('Serosa Thickness Change vs. Trauma Score')\n",
    "\n",
    "cnts = [sum([x != y for x, y in zip(y1, y2) if x == 0]),\n",
    "        sum([x == y for x, y in zip(y1, y2) if x == 1]),\n",
    "        sum([x == y for x, y in zip(y1, y2) if x == 0]),\n",
    "        sum([x != y for x, y in zip(y1, y2) if x == 1])]\n",
    "\n",
    "plt.text(-0.08, 1.25, f\"n={cnts[0]} ({100 * cnts[0] / m:.0f}%)\", size=10)\n",
    "plt.text(0.92, 1.25, f\"n={cnts[1]} ({100 * cnts[1] / m:.0f}%)\", size=10)\n",
    "plt.text(-0.08, 0.25, f\"n={cnts[2]} ({100 * cnts[2] / m:.0f}%)\", size=10)\n",
    "plt.text(0.92, 0.25, f\"n={cnts[3]} ({100 * cnts[3] / m:.0f}%)\", size=10)\n",
    "\n",
    "print('Top left N = {} / {}'.format(cnts[0], m))\n",
    "print('Top right N = {} / {}'.format(cnts[1], m))\n",
    "print('Bottom left N = {} / {}'.format(cnts[2], m))\n",
    "print('Bottom right N = {} / {}'.format(cnts[3], m))\n",
    "print('Agreement = {} / {}'.format(sum(cnts[1:3]), m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the key variable which is target stress. Below is the corresponding load in grams for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_to_megapascal(load):\n",
    "    return (9.81 * load) / (1000 * np.pi * (5/2)** 2)  # 5mm pin\n",
    "\n",
    "def megapascal_to_gram(load):\n",
    "    return (1000 * np.pi * (5/2)** 2) * load / 9.81  # 5mm pin\n",
    "\n",
    "for load in [200, 400, 600, 800, 1000, 1200]:  # test loads in grams\n",
    "    print(f\"{gram_to_megapascal(load):6.2f} (MPa) = {load:5} (grams)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_name = 'Target Stress (MPa)'\n",
    "for y_name in y.columns:\n",
    "    plt.figure()\n",
    "    plt.scatter(x=X[x_name], y=y[y_name], alpha=0.25, s=100)\n",
    "    plt.xlabel(x_name)\n",
    "    plt.ylabel(y_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal for the prediction algorithm is to provide a metric for preventing tissue damage intraoperatively. Thus it has the following requirements:\n",
    "\n",
    "1. Good overall accuracy so it is reliable without being restrictive\n",
    "2. High recall such that it is conservative, limiting the occurrence of false negatives\n",
    "3. Simple with limited input so that it can be implemented cheaply in real time\n",
    "\n",
    "Further to requirement 3 above, no histology features can be used to make the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq(crush):\n",
    "    time = crush.index\n",
    "    delta = time[1:] - time[:-1]\n",
    "    return 1 / np.mean(delta.total_seconds())\n",
    "\n",
    "freqs = crushes['Data'].apply(get_freq)\n",
    "freqs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample frequency is 31 Hz\n",
    "\n",
    "Nyquist frequency is 62 Hz\n",
    "\n",
    "Cutoff frequency of 3rd order butterworth digital filter is 0.2 * 62 = 12.4 Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "Define the targets and set the random seed for the model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['Percent Serosa Change',  # regression\n",
    "           'Significant Serosa Change',\n",
    "           'Tissue Damage',\n",
    "           'Major Tissue Damage']\n",
    "\n",
    "class_labels = {'Percent Serosa Change': None,\n",
    "                'Significant Serosa Change': ['No Change', 'Significant Change'],\n",
    "                'Tissue Damage': ['No Damage', 'Damage'],\n",
    "                'Major Tissue Damage': ['No Damage or Minor Damage', 'Major Damage']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, targ in enumerate(targets):\n",
    "    print(i, targ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_np = X.values.astype(np.float64)\n",
    "y_np = y[targets].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_np, y_np, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizing the features makes the final model harder to apply and interpret manually. So it is not advisable in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train).boxplot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X.columns.values\n",
    "for i, feat in enumerate(features):\n",
    "    print(i, feat)\n",
    "stress_feature = features[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prep\n",
    "Create functions needed for fitting predictive models to the data.\n",
    "\n",
    "For classification we will use logistic regression due to it's long standing success as a binary classificaiton model for medical data. For regression we will rely on lasso regression to take advantage of the feature selection behaviour given the number of low correlation features in the dataset. Both are also simple enough to be practical for hand calculations or lookup tables in the OR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "def logit_reg(X, y):\n",
    "    # Fit classifier using cross validation and l1 loss\n",
    "    model = LogisticRegressionCV(penalty='l1',\n",
    "                                 Cs=10,\n",
    "                                 cv=5,\n",
    "                                 scoring='accuracy',\n",
    "                                 solver='liblinear',\n",
    "                                 random_state=SEED,\n",
    "                                 max_iter=2500,\n",
    "                                 n_jobs=4)\n",
    "    return model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "def lasso_reg(X, y):\n",
    "    # Fit regressor using cross validation and l1 loss\n",
    "    model = LassoCV(n_alphas=10,\n",
    "                    cv=5,\n",
    "                    random_state=SEED,\n",
    "                    max_iter=2500,\n",
    "                    n_jobs=4)\n",
    "    return model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE, RFECV\n",
    "\n",
    "def optimal_reg(X, y, target, n_features=None):\n",
    "    # Restrict the features used to get a simpler model\n",
    "    \n",
    "    # Lasso and MSE for regression\n",
    "    if class_labels[target] is None:\n",
    "        model = lasso_reg(X, y)\n",
    "        if n_features is not None:\n",
    "            rfe = RFE(model, n_features_to_select=n_features)\n",
    "        else:\n",
    "            rfe = RFECV(model, cv=5, scoring='neg_mean_squared_error', n_jobs=4)\n",
    "    \n",
    "    # Logistic regression and accuracy for classification\n",
    "    else:\n",
    "        model = logit_reg(X, y)\n",
    "        if n_features is not None:\n",
    "            rfe = RFE(model, n_features_to_select=n_features)\n",
    "        else:\n",
    "            rfe = RFECV(model, cv=5, scoring='accuracy', n_jobs=4)\n",
    "    \n",
    "    return rfe.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create metric review functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, mean_squared_error\n",
    "\n",
    "def metrics(X, y, model, target):\n",
    "    # RMSE and fit curve for regressors\n",
    "    if class_labels[target] is None:\n",
    "        plot_fit(X, y, model, target)\n",
    "        return {'RMSE': np.sqrt(mean_squared_error(y, model.predict(X)))}\n",
    "        \n",
    "    \n",
    "    # Classification metrics and AUC for classifiers\n",
    "    plot_auc(X, y, model, target)\n",
    "    report = classification_report(y, model.predict(X),\n",
    "                                   digits=3,\n",
    "                                   output_dict=True)\n",
    "#     for i, num in enumerate(np.unique(y)):\n",
    "#         report[class_labels[target][i]] = report.pop(str(num))\n",
    "    return report['1.0']  # positive calss only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "def plot_auc(X, y, model, target):\n",
    "    plt.figure()\n",
    "    plt.plot(*roc_curve(y, model.predict_proba(X)[:, 1])[:2],\n",
    "             label=f\"ROC curve (AUC = {roc_auc_score(y, model.predict(X)):.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([-0.05, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title(target)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fit(X, y, model, target):\n",
    "    best_feat = np.argmax(np.abs(model.coef_)) \n",
    "    plt.figure()\n",
    "    plt.plot(X[:, best_feat], model.predict(X), 'k.')\n",
    "    plt.scatter(X[:, best_feat], y, alpha=0.25, s=100)\n",
    "    plt.xlabel(stress_feature)  # assumed to be best feature\n",
    "    plt.ylabel(target)\n",
    "    plt.legend(['Predicted', 'Actual'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(X, y, model, n_features=None):\n",
    "    '''\n",
    "    Convenient function  to build multiple models\n",
    "    Remove any features deemed to be irrelevent by recursive feature elimination\n",
    "    '''\n",
    "    if n_features is None:\n",
    "        n_features = X.shape[1]\n",
    "    rfe = restricted_reg(X, y, model, n_features)\n",
    "    \n",
    "    # Rank the features\n",
    "    rank = pd.DataFrame({'features': features,\n",
    "                         'ranking': rfe.ranking_})\n",
    "    rank = rank.sort_values(by='ranking')\n",
    "    selected = rank.features[:n_features].tolist()\n",
    "    \n",
    "    # Train the model once more on just the selected features\n",
    "    mask = rfe.support_\n",
    "    model = logit_reg(X[:, mask], y)\n",
    "    \n",
    "    return {'model': model,\n",
    "            'rank': rank,\n",
    "            'features': selected,\n",
    "            'n_features': n_features}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression (Linear or Logistic)\n",
    "\n",
    "Build linear regression model for the continuous targets. Build logistic regression models for the class target values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent Change in Serosa Thickness\n",
    "Regression model with Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "targets[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lasso_reg(X_train, y_train[:, ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(X_train, y_train[:, ind], model, targets[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(X_test, y_test[:, ind], model, targets[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = optimal_reg(X_train, y_train[:, ind], targets[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features[rfe.support_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(X_train[:, rfe.support_], y_train[:, ind], rfe.estimator_, targets[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(X_test[:, rfe.support_], y_test[:, ind], rfe.estimator_, targets[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = pd.DataFrame({'features': features,\n",
    "                     'ranking': rfe.ranking_})\n",
    "rank = rank.sort_values(by='ranking')\n",
    "rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significant Change in Serosa Thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 1\n",
    "targets[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = logit_reg(X_train, y_train[:, ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(X_train, y_train[:, ind], model, targets[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(X_test, y_test[:, ind], model, targets[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = optimal_reg(X_train, y_train[:, ind], targets[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features[rfe.support_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(X_train[:, rfe.support_], y_train[:, ind], rfe.estimator_, targets[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(X_test[:, rfe.support_], y_test[:, ind], rfe.estimator_, targets[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = pd.DataFrame({'features': features,\n",
    "                     'ranking': rfe.ranking_})\n",
    "rank = rank.sort_values(by='ranking')\n",
    "rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how much the performance deteriorates with only one feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = optimal_reg(X_train, y_train[:, ind], targets[ind], n_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(X_train[:, rfe.support_], y_train[:, ind], rfe.estimator_, targets[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(X_test[:, rfe.support_], y_test[:, ind], rfe.estimator_, targets[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No measureable difference!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rfe.estimator_\n",
    "print('Model coefficients:')\n",
    "print(model.coef_)\n",
    "print('Model features:')\n",
    "print(features[rfe.support_])\n",
    "print('Model intercept:')\n",
    "print(model.intercept_)\n",
    "print('Model regularization:')\n",
    "C = model.C_\n",
    "print(f\"C = {C}, lambda = {1 / C}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where does the model predict significant serosa thickness change then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress = np.linspace(0, 1, 1000).reshape(-1, 1)\n",
    "pred = model.predict(stress)\n",
    "prob = model.predict_proba(stress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(megapascal_to_gram(stress[np.argmax(pred)]), 'gram limit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(stress, pred)\n",
    "plt.scatter(stress, prob[:, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tissue Damage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 2\n",
    "targets[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = logit_reg(X_train, y_train[:, ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(X_train, y_train[:, ind], model, targets[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(X_test, y_test[:, ind], model, targets[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = optimal_reg(X_train, y_train[:, ind], targets[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features[rfe.support_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(X_train[:, rfe.support_], y_train[:, ind], rfe.estimator_, targets[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(X_test[:, rfe.support_], y_test[:, ind], rfe.estimator_, targets[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = pd.DataFrame({'features': features,\n",
    "                     'ranking': rfe.ranking_})\n",
    "rank = rank.sort_values(by='ranking')\n",
    "rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how much the performance deteriorates with only one feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = optimal_reg(X_train, y_train[:, ind], targets[ind], n_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(X_train[:, rfe.support_], y_train[:, ind], rfe.estimator_, targets[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(X_test[:, rfe.support_], y_test[:, ind], rfe.estimator_, targets[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Not a huge loss for the training set and the test set actually performs better..**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rfe.estimator_\n",
    "print('Model coefficients:')\n",
    "print(model.coef_)\n",
    "print('Model features:')\n",
    "print(features[rfe.support_])\n",
    "print('Model intercept:')\n",
    "print(model.intercept_)\n",
    "print('Model regularization:')\n",
    "C = model.C_\n",
    "print(f\"C = {C}, lambda = {1 / C}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where does the model predict tissue damage then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress = np.linspace(0, 1, 1000).reshape(-1, 1)\n",
    "pred = model.predict(stress)\n",
    "prob = model.predict_proba(stress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(megapascal_to_gram(stress[np.argmax(pred)]), 'gram limit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(stress, pred)\n",
    "plt.scatter(stress, prob[:, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Major Tissue Damage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a specific indicator from the targets and split the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 3\n",
    "targets[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = logit_reg(X_train, y_train[:, ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:, ind].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 4 positive examples for major damage!! That is far too few to build a useable model as feared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=2500, n_jobs=4, random_state=SEED)\n",
    "model.fit(X_train[:, 6].reshape(-1, 1), y_train[:, ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostress = np.linspace(0, 1, 1000).reshape(-1, 1)\n",
    "pred = model.predict(stress)\n",
    "prob = model.predict_proba(stress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(megapascal_to_gram(stress[np.argmax(pred)]), 'gram limit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(stress, pred)\n",
    "plt.scatter(stress, prob[:, 1]);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
