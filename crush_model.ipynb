{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crush Rig Predictive Models\n",
    "* __Classifier for Trauma Score__\n",
    "* __Regressor for serosal thickness delta__\n",
    "\n",
    "Written by Matt MacDonald for CIGITI at the Hospital for Sick Children Toronto\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All tools to manipulate data will be obtained from the crush_plot.py file. The objective of this notebook is to predict the histological targets from the force/position crush data using a classifier, either logistic regression or otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdb import set_trace\n",
    "from warnings import warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crush data must be collected using the crush rig and crush.py and stored in the expected folder structure at the root directory indicated by PATH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crush_read import *\n",
    "from crush_plot import *\n",
    "PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.dpi'] = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all data and modify as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = study_outline(PATH)\n",
    "targets = study_targets(PATH)\n",
    "crushes = study_data(study)\n",
    "crushes = modify(crushes)\n",
    "crushes = calculate(crushes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, legend = preprocess(crushes, targets)\n",
    "y = refine(y)\n",
    "print('Reference for categorical features:')\n",
    "legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in y.columns:\n",
    "    most_common = y[col].value_counts().idxmax()\n",
    "    s = (y[col] == most_common).sum()\n",
    "    c = y[col].count()\n",
    "    r = s / c\n",
    "    print(f\"{col}\\nBaseline Accuracy = {s}/{c} ({r:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The major tissue damage target is unbalanced. It may not be enough data for an accurate classifier due to the skewed distribution of positive samples.\n",
    "\n",
    "Generate matrix of correlations to aid understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "damage_score = y['Tissue Damage'].copy()\n",
    "damage_score[y['Major Tissue Damage']] = 2\n",
    "serosal_delta = (X['Post Serosal Thickness (mm)'] - X['Serosal Thickness (mm)']) / X['Serosal Thickness (mm)']\n",
    "serosal_delta = -serosal_delta\n",
    "plt.scatter(serosal_delta, damage_score, color='indigo')\n",
    "plt.ylabel('Tissue Damage Score')\n",
    "plt.xlabel('Serosal Thickness Change Percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "s = 0.25\n",
    "m = y.shape[0]\n",
    "y1 = y['Tissue Damage']\n",
    "y2 = y['Significant Serosal Change']\n",
    "rx = np.random.rand(m) * s - (s / 2)\n",
    "ry = np.random.rand(m) * s - (s / 2)\n",
    "plt.scatter(x=y1 + rx, y=y2 + ry, color='indigo')\n",
    "plt.xlabel('Tissue Damage')\n",
    "plt.ylabel('Significant Serosal Change')\n",
    "plt.xticks([0, 1])\n",
    "plt.yticks([0, 1])\n",
    "plt.xlim([-0.5, 1.5])\n",
    "plt.ylim([-0.5, 1.5])\n",
    "\n",
    "cnts = [sum([x != y for x, y in zip(y1, y2) if x == 0]),\n",
    "        sum([x == y for x, y in zip(y1, y2) if x == 1]),\n",
    "        sum([x == y for x, y in zip(y1, y2) if x == 0]),\n",
    "        sum([x != y for x, y in zip(y1, y2) if x == 1])]\n",
    "\n",
    "plt.text(-0.1, 1.25, f\"n = {cnts[0]}\", size=10)\n",
    "plt.text(0.9, 1.25, f\"n = {cnts[1]}\", size=10)\n",
    "plt.text(-0.1, 0.25, f\"n = {cnts[2]}\", size=10)\n",
    "plt.text(0.9, 0.25, f\"n = {cnts[3]}\", size=10)\n",
    "\n",
    "print('Top left N = {} / {}'.format(cnts[0], m))\n",
    "print('Top right N = {} / {}'.format(cnts[1], m))\n",
    "print('Bottom left N = {} / {}'.format(cnts[2], m))\n",
    "print('Bottom right N = {} / {}'.format(cnts[3], m))\n",
    "print('Agreement = {} / {}'.format(sum(cnts[1:3]), m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "W = pd.concat([X, y], axis=1)\n",
    "W_corr = W.corr(method='spearman')\n",
    "sns.heatmap(W_corr, cmap='RdBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the key variable which is target stress. Below is the corresponding load in grams for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for load in [200, 400, 600, 800, 1000, 1200]:  # test loads in grams\n",
    "    pressure = (9.81 * load) / (np.pi * (5/2)** 2)\n",
    "    print(f\"{pressure:6.0f} (kPa) = {load:5} (grams)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_name = 'Target Stress (MPa)'\n",
    "for y_name in y.columns:\n",
    "    plt.figure()\n",
    "    plt.scatter(x=X[x_name], y=y[y_name])\n",
    "    plt.xlabel(x_name)\n",
    "    plt.ylabel(y_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove any histology related features to focus on real time predictors. Also remove the holding strain since only the STOP protocol is being considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = X.copy()\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop('Pathologist (Cathy or Corwyn)', axis=1)\n",
    "X = X.drop('Serosal Thickness (mm)', axis=1)\n",
    "X = X.drop('Post Serosal Thickness (mm)', axis=1)\n",
    "X = X.drop('Holding Strain', axis=1)\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal for the prediction algorithm is to provide a metric for preventing tissue damage intraoperatively. Thus it has the following requirements:\n",
    "\n",
    "1. Good overall accuracy so it is reliable without being restrictive\n",
    "2. High recall such that it is conservative, limiting the occurrence of false negatives\n",
    "3. Simple with limited input so that it can be implemented cheaply in real time\n",
    "\n",
    "Further to requirement 3 above, no histology features can be used to make the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show correlations for the reduced feature set\n",
    "%matplotlib inline\n",
    "X_corr = X.corr(method='spearman')\n",
    "sns.heatmap(X_corr, cmap='RdBu', vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq(crush):\n",
    "    time = crush.index\n",
    "    delta = time[1:] - time[:-1]\n",
    "    return 1 / np.mean(delta.total_seconds())\n",
    "\n",
    "freqs = crushes['Data'].apply(get_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample frequency is 31 Hz\n",
    "\n",
    "Nyquist frequency is 62 Hz\n",
    "\n",
    "Cutoff frequency of 3rd order butterworth digital filter is 0.2 * 62 = 12.4 Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Build logistic regression models as a relatively simple first step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_split(X, y, seed=0, size=0.2):\n",
    "    # Convert from pandas to numpy\n",
    "    X_np = X.values.astype(np.float64)\n",
    "    y_np = y.values\n",
    "    \n",
    "    # Split into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_np, y_np, test_size=size, random_state=seed)\n",
    "    \n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_model(dataset, seed=0, scaled=False):\n",
    "    \n",
    "    # Scale input features\n",
    "    if scaled:\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(dataset[0])\n",
    "    else:\n",
    "        X = dataset[0]\n",
    "    y = dataset[1]\n",
    "    \n",
    "    # Fit logistic regression to training set\n",
    "    model = LogisticRegressionCV(penalty='l2',\n",
    "                                 solver='lbfgs',\n",
    "                                 cv=5,  # 5 or 10 recommended\n",
    "                                 refit=True,\n",
    "                                 random_state=seed,\n",
    "                                 max_iter=1000,\n",
    "                                 n_jobs=4)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    if scaled:\n",
    "        return model, scaler\n",
    "    else:\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_features(dataset, n_features, seed=0):\n",
    "    model, scaler = logreg_model(dataset, seed=seed, scaled=True)  # use scaled features to avoid bias in selection\n",
    "    rfe = RFE(model, n_features)  # pick the best n features\n",
    "    rfe = rfe.fit(*dataset) \n",
    "    return rfe, model, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_display(model, dataset, scaler=None):\n",
    "    if scaler is not None:\n",
    "        scaled_dataset = (scaler.transform(dataset[0]), dataset[1])\n",
    "    else:\n",
    "        scaled_dataset = dataset\n",
    "    logreg_auc(model, scaled_dataset, disp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_predict(model, dataset, disp=False):\n",
    "    # Predict and make a confusion matrix, optionally display results\n",
    "    X = dataset[0]\n",
    "    y = dataset[1]\n",
    "    y_pred = model.predict(X)\n",
    "    y_prob = model.predict_proba(X)\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    metrics = logreg_metrics(cm, disp=disp)\n",
    "    return {'predictions': y_pred,\n",
    "            'probabilities': y_prob,\n",
    "            'metrics': metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_metrics(cm, disp=False):\n",
    "    tp = cm[1][1]\n",
    "    tn = cm[0][0]\n",
    "    fp = cm[0][1]\n",
    "    fn = cm[1][0]\n",
    "    accuracy = (tp + tn) / cm.sum()\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1score = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    if disp:\n",
    "        print(f'F1 Score = {f1score:.2f}')\n",
    "        print(f'Accuracy = {accuracy:.2f}')\n",
    "        print(f'Precision = {precision:.2f}')\n",
    "        print(f'Recall = {recall:.2f}')\n",
    "    \n",
    "    return np.round([f1score, accuracy, precision, recall], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_auc(model, dataset, disp=True):\n",
    "    X = dataset[0]\n",
    "    y = dataset[1]\n",
    "    y_pred = logreg_predict(model, dataset, disp=disp)['predictions']\n",
    "    logit_roc_auc = roc_auc_score(y, y_pred)\n",
    "    \n",
    "    if disp:\n",
    "        print(classification_report(y, y_pred))\n",
    "        vals = roc_curve(y, model.predict_proba(X)[:,1])\n",
    "        plt.figure()\n",
    "        plt.plot(*vals[:2], label=f\"ROC curve (A = {logit_roc_auc:.2f})\")\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([-0.05, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()\n",
    "        \n",
    "    return logit_roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_decision_bndr(model, dataset, n1, features=None, labels=['False', 'True']):\n",
    "    # Plot a series of 2D decision boundaries freezing the other features to mean values\n",
    "    # dataset=(X, y) ideally of the test set and n1 is the primary feature being compared (default stress)\n",
    "    \n",
    "    X_set, y_set = dataset[0], dataset[1]\n",
    "    X_avg = np.mean(X_set, axis=0).reshape(1, -1)\n",
    "    n = X_set.shape[1]\n",
    "    m = y_set.size\n",
    "    \n",
    "    if features is None:\n",
    "        features = []\n",
    "        for num in range(n):\n",
    "            features.append(f\"Feature {n}\")\n",
    "    \n",
    "    def model_grid(grid1, grid2, n1, n2):\n",
    "        # Predict for two 2D grids of features\n",
    "        s = grid1.shape\n",
    "        Z = np.zeros(s)\n",
    "        for i in range(s[0]):\n",
    "            for j in range(s[1]):\n",
    "                X = X_avg\n",
    "                X[0, n1] = grid1[i, j]\n",
    "                X[0, n2] = grid2[i, j]\n",
    "                Z[i, j] = model.predict(X)\n",
    "        return Z\n",
    "\n",
    "    # Visualize the decision boundary\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    colors = ('blue', 'red')\n",
    "    alt_colors = ('cornflowerblue', 'lightcoral')\n",
    "    \n",
    "    for n2 in range(n):\n",
    "        if (n1 == n2) and (n > 1):\n",
    "            continue\n",
    "        maxx = X_set[:, n1].max()\n",
    "        maxy = X_set[:, n2].max()\n",
    "        minx = X_set[:, n1].min()\n",
    "        miny = X_set[:, n2].min()\n",
    "        rx = maxx - minx\n",
    "        ry = maxy - miny\n",
    "        f = 0.2\n",
    "        X1, X2 = np.meshgrid(np.linspace(minx - f*rx, maxx + f*rx, 100),\n",
    "                             np.linspace(miny - f*ry, maxy + f*ry, 100))\n",
    "        Z = model_grid(X1, X2, n1, n2)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.contourf(X1, X2, Z, alpha=0.50, cmap=ListedColormap(colors))\n",
    "        plt.xlim(X1.min(), X1.max())\n",
    "        plt.ylim(X2.min(), X2.max())\n",
    "        for res in np.unique(y_set):\n",
    "            color = colors[0] if (res == False) else colors[1]\n",
    "            plt.scatter(X_set[y_set == res, n1], X_set[y_set == res, n2],\n",
    "                        c=color, label=labels[int(res)])\n",
    "        plt.title(f'Classification (N={m})')\n",
    "        plt.xlabel(features[n1])\n",
    "        plt.ylabel(features[n2])\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_scale(dataset, scaler):\n",
    "    return (scaler.transform(dataset[0]), dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_build(X, y, n_features=None, seed=0):\n",
    "    '''\n",
    "    Convenient function  to build multiple logistic regression models\n",
    "    '''\n",
    "    \n",
    "    # Select a specific indicator from the targets and split the dataset\n",
    "    dataset_train, dataset_test = logreg_split(X, y, seed=seed)\n",
    "    \n",
    "    # Remove any features deemed to be irrelevent by recursive feature elimination\n",
    "    if n_features is None:\n",
    "        n_features = X.shape[1]\n",
    "    rfe, model, scaler = logreg_features(dataset_train, n_features, seed=seed)\n",
    "    \n",
    "    # Rank the features\n",
    "    rank = pd.DataFrame({'feature': X.columns.values,\n",
    "                         'support': rfe.support_,\n",
    "                         'ranking': rfe.ranking_})\n",
    "    rank = rank.sort_values(by='ranking')\n",
    "    features = rank.feature[:n_features].tolist()\n",
    "    \n",
    "    # Train the model once more on just the selected features\n",
    "    dataset_train, dataset_test = logreg_split(X[features], y, seed=seed)\n",
    "    model = logreg_model(dataset_train, seed=seed)  # no scaling\n",
    "    \n",
    "    # Check performance on the training set\n",
    "    pred_train = logreg_predict(model, dataset_train)\n",
    "    \n",
    "    # Check performance on the test set for comparison\n",
    "    pred_test = logreg_predict(model, dataset_test)\n",
    "    \n",
    "    return {'model': model,\n",
    "            'rank': rank,\n",
    "            'features': features,\n",
    "            'n_features': n_features,\n",
    "            'train_metrics': pred_train['metrics'],\n",
    "            'test_metrics': pred_test['metrics']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the targets and the random seed for the model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "indicators = ['Significant Serosal Change',\n",
    "              'Tissue Damage',\n",
    "              'Major Tissue Damage']\n",
    "indicator_labels = {'Significant Serosal Change': ['No Change', 'Significant Change'],\n",
    "                    'Tissue Damage': ['No Damage', 'Damage'],\n",
    "                    'Major Tissue Damage': ['No Damage or Minor Damage', 'Major Damage']}\n",
    "y.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serosal Thickness Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = indicators[0]\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for n in range(X.shape[1]):\n",
    "    res = logreg_build(X, y[ind], n_features=(n + 1), seed=SEED)\n",
    "    df = df.append(res, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 1\n",
    "idx = (df.n_features == n_features).idxmax()\n",
    "model = df.model[idx]\n",
    "features = df.features[idx]\n",
    "dataset_train, dataset_test = logreg_split(X[features], y[ind], seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training set performance\n",
    "logreg_display(model, dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check test set performance\n",
    "logreg_display(model, dataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model coefficients:')\n",
    "print(model.coef_)\n",
    "print('Model features:')\n",
    "print(features)\n",
    "print('Model intercept:')\n",
    "print(model.intercept_)\n",
    "print('Model regularization:')\n",
    "C = model.C_\n",
    "print(f\"C = {C}, lambda = {1 / C}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run an example to confirm the model equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict_proba(dataset_test[0])\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = dataset_test[0][1, :]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = example @ model.coef_.T + model.intercept_\n",
    "odds = np.exp(logit)\n",
    "prob = odds / (1 + odds)\n",
    "print(logit, odds, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(example @ model.coef_.T + model.intercept_) / (1 + np.exp(example @ model.coef_.T + model.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.exp(- (example @ model.coef_.T) - model.intercept_) + 1) ** -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE MANUALLY\n",
    "# (1 + np.exp(1.326 + 0.25*(0) - 4.316*(0.6059) - 0.25*(0.00835) - 1.046*(0.2368))) ** -1\n",
    "(1 + np.exp(1.257 - 4.415*(0.6059))) ** -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot decision boundaries for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = features.index('Target Stress (MPa)')\n",
    "logreg_decision_bndr(model, dataset_test, n1, features=features, labels=indicator_labels[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tissue Damage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a specific indicator from the targets and split the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = indicators[1]\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stress alone\n",
    "logreg_build(X[['Target Stress (MPa)']], y[ind], seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for n in range(X.shape[1]):\n",
    "    res = logreg_build(X, y[ind], n_features=(n + 1), seed=SEED)\n",
    "    df = df.append(res, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.features[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A high accuracy can be achieved with just stress and strain as input features. Reducing further to just strain dramatically decreases accuracy. Reducing to just stress reduces recall to 80%. A perfect prediction performance on the test set can be achieved if tissue type, gender and relaxation stress are included as well making it the most accurate model although harder to implement in real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 2\n",
    "idx = (df.n_features == n_features).idxmax()\n",
    "model = df.model[idx]\n",
    "features = df.features[idx]\n",
    "dataset_train, dataset_test = logreg_split(X[features], y[ind], seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training set performance\n",
    "logreg_display(model, dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check test set performance\n",
    "logreg_display(model, dataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model coefficients:')\n",
    "print(model.coef_)\n",
    "print('Model features:')\n",
    "print(features)\n",
    "print('Model intercept:')\n",
    "print(model.intercept_)\n",
    "print('Model regularization:')\n",
    "C = model.C_\n",
    "print(f\"C = {C}, lambda = {1 / C}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run an example to confirm the model equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict_proba(dataset_test[0])\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = dataset_test[0][1, :]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = example @ model.coef_.T + model.intercept_\n",
    "odds = np.exp(logit)\n",
    "prob = odds / (1 + odds)\n",
    "print(logit, odds, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(example @ model.coef_.T + model.intercept_) / (1 + np.exp(example @ model.coef_.T + model.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.exp(- (example @ model.coef_.T) - model.intercept_) + 1) ** -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE MANUALLY\n",
    "# (1 + np.exp(2.94*(0) - 17.84*(0.6059) - 4.95*(0.2368) + 15.54*(0.7923) - 6.65)) ** -1\n",
    "(1 + np.exp(-17.09*(0.6059) + 18.45*(0.7923) - 8.97)) ** -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 + np.exp(-17.1*(0.6059) + 18.5*(0.7923) - 9)) ** -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test[0][5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 + np.exp(-17.1*(0.10344) + 18.5*(0.637) - 9)) ** -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot decision boundaries for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = features.index('Target Stress (MPa)')\n",
    "logreg_decision_bndr(model, dataset_train, n1, features=features, labels=indicator_labels[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Major Tissue Damage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a specific indicator from the targets and split the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = indicators[2]\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only 3 positive examples for major damage!!\n",
    "y[ind].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, 3 positive samples for major damage is not enough to form a useful model. So instead an anomaly detection algorithm will be applied to look for deviations from the normal expectation. For simplicity the validation will be excluded."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
